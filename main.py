""" This Project aims at generating a pose extraction classifier
    It follows PEP8 coding conventions
    TensorFlow version: 1.10.0 """
import tensorflow as tf
import numpy as np
import time
import matplotlib.pyplot as plt
import random
import pickle


def conv_network(x):
    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))
    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))
    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))

    # A fancy CNN which is recommended for Cifar dataset
    # credits to https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c
    # I changed the model to 3 layers <- subject to changes
    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1, 1, 1, 1], padding='SAME')
    conv1 = tf.nn.relu(conv1)
    conv1_pool = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
    conv1_bn = tf.layers.batch_normalization(conv1_pool)

    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1, 1, 1, 1], padding='SAME')
    conv2 = tf.nn.relu(conv2)
    conv2_pool = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
    conv2_bn = tf.layers.batch_normalization(conv2_pool)

    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1, 1, 1, 1], padding='SAME')
    conv3 = tf.nn.softmax(conv3)
    conv3_pool = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
    conv3_bn = tf.layers.batch_normalization(conv3_pool)

    flat = tf.contrib.layers.flatten(conv3_bn)

    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=256, activation_fn=tf.nn.relu)
    full1 = tf.nn.dropout(full1, keep_prob=0.8)
    full1 = tf.layers.batch_normalization(full1)

    out = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=512, activation_fn=tf.nn.relu)

    return out


if __name__ == "__main__":
    # loading data
    data_file = open('youtube_train_data.pkl', 'rb')
    train_data, train_labels = pickle.load(data_file)
    train_data = train_data.astype(np.float32)
    data_file.close()

    # hyper parameters
    batch_size = 32
    epoch_batch = 32
    num_epoch = 50
    learning_rate = 0.002
    num_units = 64
    seq_length = 10

    # pickup the last batch for visualization
    last_batch = len(train_data) - batch_size - 1
    x_show, y_show = train_data[last_batch: last_batch + batch_size], \
                     train_labels[last_batch: last_batch + batch_size]

    show_original = x_show[-1, -1]
    show_labels = y_show[-1, -1]

    # normalize
    train_data -= np.mean(train_data, axis=(2, 3, 4), keepdims=True)
    train_data /= np.std(train_data, axis=(2, 3, 4), keepdims=True)

    valid_data, valid_labels = train_data[:256], train_labels[:256].reshape(-1, seq_length, 14)
    train_data, train_labels = train_data[256-1:], train_labels[256-1:].reshape(-1, seq_length, 14)

    # make the visualization data consistent after normalization
    last_batch = len(train_data) - batch_size - 1
    x_show, y_show = train_data[last_batch: last_batch + batch_size], \
                     train_labels[last_batch: last_batch + batch_size]

    # tracking the losses and labels
    loss_train_list = []
    loss_valid_list = []
    # track_label_list = []
    # track_predict_list = []

    # Remove previous weights, bias, inputs, etc..
    tf.reset_default_graph()

    # filters
    w_fc = tf.Variable(tf.truncated_normal(shape=[num_units, 14], mean=0, stddev=0.1), name='w_fc')
    b_fc = tf.Variable(tf.random_normal(shape=[], mean=0, stddev=0.1), name='b_fc')

    # each time the CNN takes in a set of 10 images and spit out 10 vectors
    x = tf.placeholder(tf.float32, shape=(None, seq_length, 64, 64, 3), name='input_x')
    y = tf.placeholder(tf.float32, shape=(None, seq_length, 14), name='input_y')

    rnn_input = tf.zeros([0, seq_length, 512])
    for i in range(batch_size):
        feed_in_CNN = tf.squeeze(tf.slice(x, [i, 0, 0, 0, 0], [1, seq_length, 64, 64, 3]), [0])
        # vectors generated by the CNN
        temp = conv_network(feed_in_CNN)  # (10, 512)
        rnn_input = tf.concat([rnn_input, tf.expand_dims(temp, 0)], 0)

    # the LSTM cell of the RNN
    lstm = tf.nn.rnn_cell.LSTMCell(num_units)
    h_val, _ = tf.nn.dynamic_rnn(lstm, rnn_input, dtype=tf.float32)

    # collection of all the final output
    final_output = tf.zeros(shape=[batch_size, 0, 14])
    for i in np.arange(seq_length):
        temp = tf.reshape(h_val[:, i, :], [batch_size, num_units])
        output = tf.matmul(temp, w_fc) + b_fc
        output = tf.reshape(output, [-1, 1, 14])
        final_output = tf.concat([final_output, output], axis=1)

    predicted = final_output

    # Save the model
    tf.get_collection('validation_nodes')
    # Add opts to the collection
    tf.add_to_collection('validation_nodes', x)
    tf.add_to_collection('validation_nodes', y)
    tf.add_to_collection('validation_nodes', predicted)

    loss = tf.losses.mean_squared_error(labels = y, predictions = predicted)
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)

    saver = tf.train.Saver()

    with tf.Session() as sess:
        # Initializing the variables
        sess.run(tf.global_variables_initializer())

        # Training
        for epoch in range(num_epoch):
            # Loop over random batches
            for batch in range(epoch_batch):
                start_in_batch = random.randint(0, len(train_data) - batch_size - 1)
                x_batch, y_batch = train_data[start_in_batch: start_in_batch + batch_size], \
                                   train_labels[start_in_batch: start_in_batch + batch_size]
                sess.run(optimizer, feed_dict={x: x_batch, y: y_batch})

            print('Epoch {:>2}: '.format(epoch + 1), end='')

            start_in_batch = random.randint(0, len(valid_data) - batch_size - 1)
            x_valid, y_valid = valid_data[start_in_batch: start_in_batch + batch_size], \
                               valid_labels[start_in_batch: start_in_batch + batch_size]

            loss_train = sess.run(loss, feed_dict={x: x_batch, y: y_batch})
            loss_valid = sess.run(loss, feed_dict={x: x_valid, y: y_valid})
            print('loss on train data: {:1.4f}, loss on test data: {:.4f}'.format(loss_train, loss_valid))

            loss_train_list.append(loss_train)
            loss_valid_list.append(loss_valid)

            # visualization:
            # show_predicted = sess.run(predicted, feed_dict={x: x_show, y: y_show})
            #
            # plt.figure()
            # plt.imshow(show_original)
            # points = np.reshape(show_predicted[-1, -1], [7, 2])
            # # predicted
            # for i in range(7):
            #     plt.scatter(points[i,0], points[i,1], c='blue', marker='o')
            # # labels
            # for i in range(7):
            #     plt.scatter(show_labels[i, 0], show_labels[i, 1], c='red', marker='x')
            # plt.savefig("./joints_{}.png".format(epoch+1))
            # plt.clf()

        # this saver.save() should be within the same tf.Session() after the training is done
        save_path = saver.save(sess, "./my_model")

        # gathering validation data on 256 sequences
        track_valid = []
        track_predicted = []
        errors = [[] for _ in range(7)]
        for i in range(8):
            begin_batch = i*batch_size

            x_valid, y_valid = valid_data[begin_batch: begin_batch + batch_size], \
                               valid_labels[begin_batch: begin_batch + batch_size]

            track_valid.append(y_valid)
            track_predicted.append(sess.run(predicted, feed_dict={x: x_valid, y: y_valid}))

        for i in range(8):
            for j in range(batch_size):
                for k in range(seq_length):
                    for l in range(7):
                        errors[l].append(
                            np.sqrt(
                                np.square(track_valid[i][j, k, 2*l] - track_predicted[i][j, k, 2*l]) +
                                np.square(track_valid[i][j, k, 2*l+1] - track_predicted[i][j, k, 2*l+1])
                            )
                        )

        accu_record = [[] for _ in range(7)]
        for m in range(40):
            for i in range(7):
                accu_record[i].append(len([ _ for _ in errors[i] if _ <= m/2.0])/len(errors[i]))

        accu_rec_np = np.array(accu_record)
        accu_overall = np.mean(accu_rec_np, axis=0)

        #  Head, right wrist, left wrist, right elbow, left elbow, right shoulder, and the left shoulder
        Head_joint = accu_rec_np[0, :]
        Right_Wrist = accu_rec_np[1, :]
        Left_Wrist = accu_rec_np[2, :]
        Right_Elbow = accu_rec_np[3, :]
        Left_Elbow = accu_rec_np[4, :]
        Right_Shoulder = accu_rec_np[5, :]
        Left_Shoulder = accu_rec_np[6, :]

        plt.plot([0.5 * i for i in range(40)], Head_joint, label="Head")
        plt.plot([0.5 * i for i in range(40)], Right_Wrist, label="Right Wrist")
        plt.plot([0.5 * i for i in range(40)], Left_Wrist, label="Left Wrist")
        plt.plot([0.5 * i for i in range(40)], Right_Elbow, label="Right Elbow")
        plt.plot([0.5 * i for i in range(40)], Left_Elbow, label="Left Elbow")
        plt.plot([0.5 * i for i in range(40)], Right_Shoulder, label="Right Shoulder")
        plt.plot([0.5 * i for i in range(40)], Left_Shoulder, label="Left Shoulder")
        plt.legend(loc='upper left')
        plt.xlabel('pixels')
        plt.show()